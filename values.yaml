clusterName: &clusterName kafka
kafkaVersion: &kafkaVersion 3.8.0

clusterGenerateCertificateAuthority: true
clientsGenerateCertificateAuthority: true
kafka:
  annotations: {}
  version: *kafkaVersion
  mode: kraft
  replicas: 3
  listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
    - name: dev
      port: 9094
      type: nodeport
      tls: false
#      authentication:
#        type: oauth
#        validIssuerUri: http://keycloak/realms/kafka-authz
#        jwksEndpointUri: http://keycloak/realms/kafka-authz/protocol/openid-connect/certs
#        userNameClaim: preferred_username
#        checkAccessTokenType: false
#        customClaimCheck: "@.typ && @.typ == 'Bearer'"
#        maxSecondsWithoutReauthentication: 3600
#    - name: oauth
#      port: 9093
#      type: internal
#      tls: true
#  authorization:
#    type: keycloak
#    tokenEndpointUri: http://keycloak/realms/kafka-authz/protocol/openid-connect/token
#    delegateToKafkaAcls: true
#    clientId: kafka
#    tlsTrustedCertificates:
#      - secretName: keycloak-ca-cert
#        pattern: "*.crt"
  config:
    offsets.topic.replication.factor: 3
    transaction.state.log.replication.factor: 3
    transaction.state.log.min.isr: 2
    default.replication.factor: 3
    min.insync.replicas: 2
#    security.inter.broker.protocol: SSL
#    sasl.enabled.mechanisms: OAUTHBEARER
  storage:
    type: persistent-claim
    size: 10Gi
    deleteClaim: false
  logging:
    type: inline
    loggers:
      log4j.logger.io.strimzi: "INFO"
      log4j.logger.kafka: "INFO"
      log4j.logger.org.apache.kafka: "INFO"
nodePools:
  - name: mixed
    replicas: 3
    roles:
      - controller
      - broker
    storage:
      type: persistent-claim
      size: 10Gi
      deleteClaim: false
topics:
  - name: connect-cluster-offsets
    partitions: 1
    replicas: 3
    config:
      cleanup.policy: compact
  - name: connect-cluster-configs
    partitions: 1
    replicas: 3
    config:
      cleanup.policy: compact
  - name: connect-cluster-status
    partitions: 1
    replicas: 3
    config:
      cleanup.policy: compact
kafkaConnect:
  - name: debezium-pg
    version: *kafkaVersion
    image: ratiborec/kafkaconnect-debezium-postgres:2.7.3.Final
    replicas: 1
    annotations:
      strimzi.io/restart: "true"
    bootstrapServers: kafka-kafka-bootstrap.kafka.svc.cluster.local:9092
    tls: {}
#      trustedCertificates:
#        - secretName: kafka-cluster-ca-cert
#          pattern: "*.crt"
    authentication: {}
#      type: ""
#      certificateAndKey:
#        # just to test
#        secretName: kafka-cluster-operator-certs
#        certificate: cluster-operator.crt
#        key: cluster-operator.key
    config:
      config.providers: secrets
      config.providers.secrets.class: io.strimzi.kafka.KubernetesSecretConfigProvider
      group.id: *clusterName
      offset.storage.topic: connect-cluster-offsets
      config.storage.topic: connect-cluster-configs
      status.storage.topic: connect-cluster-status
      config.storage.replication.factor: -1
      offset.storage.replication.factor: -1
      status.storage.replication.factor: -1
kafkaConnectors:
  - name: debezium-pg-keycloak
    connectName: debezium-pg
    class: io.debezium.connector.postgresql.PostgresConnector
    taskMax: 1
    autoRestart:
      enabled: true
    config:
      offset.storage.file.filename: /debezium/data/offsets.dat
      database.history: io.debezium.relational.history.FileDatabaseHistory
      snapshot.mode: always
      database.hostname: keycloak-postgresql
      database.port: 5432
      database.user: postgres
      database.password: "postgres"
      database.dbname: bitnami_keycloak
      plugin.name: pgoutput
      topic.prefix: bn_keycloak
  - name: debezium-pg-custom
    connectName: debezium-pg
    class: "io.debezium.connector.jdbc.JdbcSinkConnector"
    taskMax: 1
    autoRestart:
      enabled: true
    config:
      connection.url: "jdbc:postgresql://keycloak-postgresql:5432/custom"
      connection.username: postgres
      connection.password: postgres
      transforms: unwrap
      topics: "bn_keycloak.public.employees"
      transforms.unwrap.type: "io.debezium.transforms.ExtractNewRecordState"
      auto.create: true
      insert.mode: upsert
      primary.key.mode: record_value
      primary.key.fields: "id"
      schema.evolution: basic

test: {}
#      quote.identifiers: true
#      topics: "bn_keycloak.public.employees"
#      table.name.format: "${source.table}"
#      key.converter: "org.apache.kafka.connect.json.JsonConverter"
#      value.converter: "org.apache.kafka.connect.json.JsonConverter"
#      key.converter.schemas.enable: true
#      value.converter.schemas.enable: true

kafka-ui:
  enabled: true
  yamlApplicationConfig:
    kafka:
      clusters:
        - name: *clusterName
          bootstrapServers: kafka-kafka-bootstrap.kafka.svc.cluster.local:9093
        - name: kafka-http
          bootstrapServers: kafka-kafka-bootstrap.kafka.svc.cluster.local:9092
    auth:
      type: disabled
    management:
      health:
        ldap:
          enabled: false
